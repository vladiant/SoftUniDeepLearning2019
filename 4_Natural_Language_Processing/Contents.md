# Natural Language Processing

* Sequential models: intro
* RNNs, bi-directional RNNs
* Gated units: GRUs
* LSTM layers
* Word embeddings, Word2Vec, GloVe
* Beam search

## Links
* [Attention in Long Short-Term Memory Recurrent Neural Networks](https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/)
* [Show, Attend and Tell: Neural Image CaptionGeneration with Visual Attention](https://arxiv.org/pdf/1502.03044.pdf)
* [Beam Search — A Search Strategy](https://hackernoon.com/beam-search-a-search-strategy-5d92fb7817f)
* [A Beginner's Guide to Word2Vec and Neural Word Embeddings](https://pathmind.com/wiki/word2vec)
* [Linguistic Regularities in Continuous Space Word Representations](https://www.aclweb.org/anthology/N13-1090/)
* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Long Short-Term Memory](http://www.bioinf.jku.at/publications/older/2604.pdf)
* [Learning Phrase Representations using RNN Encoder–Decoderfor Statistical Machine Translation](https://arxiv.org/pdf/1406.1078v3.pdf)
* [Word embeddings](https://www.tensorflow.org/tutorials/text/word_embeddings)

