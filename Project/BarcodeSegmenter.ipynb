{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barcode Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcodes are widely used to localize items on images. Numerous applications are available to find and recognize the barcodes. However they cannot manage cases such as targets with small scale, oclusions, shape deformations, noise and blurring. The most widely solutions require the barcode to be oriented in single directions and may fail in conditions that seem without problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work attempts to solve the problem of barcode localization using a deep learning based segmentation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the folder where the images datasets are loaded/present and where the \n",
    "WORKPLACE_FOLDER = \"/tmp\"\n",
    "\n",
    "# Folder to store/read checkpoints for model training\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "\n",
    "# Image size for the input\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Image size + channels for the input\n",
    "INPUT_IMAGE_SIZE = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "\n",
    "RESUME_MODELS = True\n",
    "TRAIN_MODELS = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total five datasets are used - two to train the neural network and three to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First three datasets are downloaded from http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html (ARTELAB) [[1](#ref_1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks for the segments containing barcodes were created using the [pyzbar](https://pypi.org/project/pyzbar/pyzbar) library. For this purpose the image was rotated with predefined steps and the obtained from [pyzbar](https://pypi.org/project/pyzbar/pyzbar) points were used to set the required segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has to be noted that the [pyzbar](https://pypi.org/project/pyzbar/pyzbar) did not produced reliable results even for some images that seemed without defects. For this reason not all the images from [ARTELAB](http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html) were used. Only the successfully generated masks were applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices with autofocus - first subset.\n",
    "Contains 122 images (originals + masks) with zipped size 38,5 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 18MFEr2iekIojLwEhzswOIyW_Fp8CNQA5 into /tmp/Dataset1.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"18MFEr2iekIojLwEhzswOIyW_Fp8CNQA5\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset1.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices with autofocus - first subset.\n",
    "Contains 76 images (originals + masks) with zipped size 124,5 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1SHJi744MZV40Mp38m6RW8PeuQktbEt6u into /tmp/Dataset2.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1SHJi744MZV40Mp38m6RW8PeuQktbEt6u\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset2.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices without autofocus. Contains 61 images (originals + masks) with zipped size 13,6 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1ybx4TiciMoQcpVi3fAzZoUOuSg2WPrvI into /tmp/Dataset3.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1ybx4TiciMoQcpVi3fAzZoUOuSg2WPrvI\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset3.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded from https://github.com/rohrlaf/SlaRle.js/tree/master/Muenster%20BarcodeDB and referenced as Muenster BarodeDB [[2](#ref_2)]. Masks were prepared following the above mentioned procedure with [pyzbar](https://pypi.org/project/pyzbar/pyzbar) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains 863 images (originals + masks) with zipped size 46,9 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1gfxKTaG7tHDDK5fPQW6PH-Zcbx7KPXzO into /tmp/Dataset4.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1gfxKTaG7tHDDK5fPQW6PH-Zcbx7KPXzO\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset4.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded from http://artelab.dista.uninsubria.it/downloads/datasets/barcode/hough_barcode_1d/hough_barcode_1d.html (ARTELAB) [[3](#ref_3)] Referenced as dataset no.2 plain (1d_barcode_extended_plain.zip) contains only the images and the detection masks. Masks had to be adjusted to be grayscale one channel images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains 365 images (originals + masks) with zipped size 37,5 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1rNi26q-iq5Q4BtrIOT-pDSleCtKzw3pk into /tmp/Dataset5.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1rNi26q-iq5Q4BtrIOT-pDSleCtKzw3pk\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset5.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(base_dir):\n",
    "    \"\"\"\n",
    "    Returns the filenames for barcodes and masks\n",
    "    Assumes the following structure:\n",
    "    |---base_dir\n",
    "    | |---Original\n",
    "    | | |---image1.jpg\n",
    "    | | |---image2.jpg\n",
    "    | |---Detection\n",
    "    | | |---image1.png\n",
    "    | | |---image2.png\n",
    "    \n",
    "    :param base_dir: directories where image databse is stored\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filenames = {}\n",
    "    filenames[\"Original\"] = []\n",
    "    filenames[\"Detection\"] = []\n",
    "    \n",
    "    # True if image is to be rotated counter-clockwise by 90 degrees.\n",
    "    filenames[\"Rotation\"] = []\n",
    "    \n",
    "    original_directory = os.path.join(base_dir,\"Original\")\n",
    "    detection_directory = os.path.join(base_dir,\"Detection\")\n",
    "    for file_name in os.listdir(original_directory):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            original_name = os.path.join(original_directory, file_name)\n",
    "            base_filename=os.path.splitext(file_name)[0]\n",
    "            detection_name = os.path.join(detection_directory, base_filename + \".png\")\n",
    "            if os.path.exists(detection_name):\n",
    "                filenames[\"Rotation\"].append(True)\n",
    "                filenames[\"Original\"].append(original_name)\n",
    "                filenames[\"Detection\"].append(detection_name)\n",
    "                filenames[\"Rotation\"].append(False)\n",
    "                filenames[\"Original\"].append(original_name)\n",
    "                filenames[\"Detection\"].append(detection_name)\n",
    "        \n",
    "    return pd.DataFrame(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_dataset_1 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset1\"))\n",
    "filenames_dataset_2 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset2\"))\n",
    "filenames_dataset_3 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset3\"))\n",
    "filenames_dataset_4 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset4\"))\n",
    "filenames_dataset_5 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_1.shape[0] == 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_2.shape[0] == 152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_3.shape[0] == 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_4.shape[0] == 1726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_5.shape[0] == 730)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(x):\n",
    "    # Normalize\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[..., ::-1]\n",
    "    return x\n",
    "\n",
    "def read_and_prepare_image(original_image_filename, mask_image_filename, is_rotated):\n",
    "    # Get images\n",
    "    original_image = tf.io.read_file(original_image_filename)\n",
    "    original_image_decoded = tf.image.decode_jpeg(original_image)\n",
    "    mask_image = tf.io.read_file(mask_image_filename)\n",
    "    mask_image_decoded = tf.image.decode_jpeg(mask_image)\n",
    "    \n",
    "    # Resize\n",
    "    original_image_resized = tf.image.resize(original_image_decoded, IMAGE_SIZE)\n",
    "    mask_image_resized = tf.image.resize(mask_image_decoded, IMAGE_SIZE)\n",
    "    \n",
    "    # Rotate\n",
    "    if is_rotated:\n",
    "        original_image_resized = tf.image.rot90(original_image_resized)\n",
    "        mask_image_resized = tf.image.rot90(mask_image_resized)\n",
    "\n",
    "    original_image_tensor = preprocess_image(original_image_resized)\n",
    "    mask_image_tensor = preprocess_image(mask_image_resized)\n",
    "    \n",
    "    return original_image_tensor, mask_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tf_dataset(data, should_batch = True, should_repeat = True):\n",
    "    dataset_initial = tf.data.Dataset.from_tensor_slices((data.Original.values, data.Detection.values, data.Rotation.values))\n",
    "    dataset_mapped = dataset_initial.map(read_and_prepare_image)\n",
    "    dataset_shuffled = dataset_mapped.shuffle(buffer_size = len(data))\n",
    "    \n",
    "    if should_batch:\n",
    "        dataset = dataset_shuffled.batch(BATCH_SIZE)\n",
    "    else:\n",
    "        dataset = dataset_shuffled.batch(len(data))\n",
    "        \n",
    "    if should_repeat:\n",
    "        dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = initialize_tf_dataset(filenames_dataset_4)\n",
    "train_data_2 = initialize_tf_dataset(filenames_dataset_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_map = {\n",
    "    train_data_1 : \"train1\",\n",
    "    train_data_2 : \"train2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = initialize_tf_dataset(filenames_dataset_1, should_batch = False, should_repeat = False)\n",
    "test_data_2 = initialize_tf_dataset(filenames_dataset_2, should_batch = False, should_repeat = False)\n",
    "test_data_3 = initialize_tf_dataset(filenames_dataset_3, should_batch = False, should_repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_map = {\n",
    "    test_data_1 : \"test1\",\n",
    "    test_data_2 : \"test2\",\n",
    "    test_data_3 : \"test3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data_map.keys():\n",
    "    for batch in data:\n",
    "        assert(batch[0].shape[0] == BATCH_SIZE)\n",
    "        assert(batch[0].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[0].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[0].shape[3] == INPUT_IMAGE_SIZE[2])\n",
    "        assert(batch[1].shape[0] == BATCH_SIZE)\n",
    "        assert(batch[1].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[1].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[1].shape[3] == 1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, filenames in zip(test_data_map.keys(),\n",
    "                           [filenames_dataset_1, filenames_dataset_2, filenames_dataset_3]):\n",
    "    for batch in data:\n",
    "        assert(batch[0].shape[0] == filenames.shape[0])\n",
    "        assert(batch[0].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[0].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[0].shape[3] == INPUT_IMAGE_SIZE[2])\n",
    "        assert(batch[1].shape[0] == filenames.shape[0])\n",
    "        assert(batch[1].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[1].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[1].shape[3] == 1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_4lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_5lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(128,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(128, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w_map = {\n",
    "    get_model_2lw() : \"model2lw\",\n",
    "    get_model_3lw() : \"model3lw\",\n",
    "    get_model_4lw() : \"model4lw\",\n",
    "    get_model_5lw() : \"model5lw\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_4ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_5ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n_map = {\n",
    "    get_model_2ln() : \"model2ln\",\n",
    "    get_model_3ln() : \"model3ln\",\n",
    "    get_model_4ln() : \"model4ln\",\n",
    "    get_model_5ln() : \"model5ln\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 112, 112, 16)      1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 8)       1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 224, 224, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 224, 224, 1)       9         \n",
      "=================================================================\n",
      "Total params: 4,945\n",
      "Trainable params: 4,913\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 56, 56, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 8)       1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 224, 224, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 224, 224, 1)       9         \n",
      "=================================================================\n",
      "Total params: 21,201\n",
      "Trainable params: 21,137\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 112, 112, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 112, 112, 8)       1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 224, 224, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 224, 224, 1)       9         \n",
      "=================================================================\n",
      "Total params: 85,969\n",
      "Trainable params: 85,841\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 224, 224, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 112, 112, 16)      1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 56, 56, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 112, 112, 8)       1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling (None, 224, 224, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 224, 224, 1)       9         \n",
      "=================================================================\n",
      "Total params: 344,529\n",
      "Trainable params: 344,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in model_w_map.keys():\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 8)       32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,305\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 5,417\n",
      "Trainable params: 5,385\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 21,673\n",
      "Trainable params: 21,609\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 86,441\n",
      "Trainable params: 86,313\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in model_n_map.keys():\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_train_1 = round(len(filenames_dataset_4) * 1.0 / BATCH_SIZE)\n",
    "steps_per_epoch_train_2 = round(len(filenames_dataset_5) * 1.0 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_map = {\n",
    "    train_data_1 : steps_per_epoch_train_1,\n",
    "    train_data_2 : steps_per_epoch_train_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CHECKPOINTS_DIR):\n",
    "    os.makedirs(CHECKPOINTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 36s 666ms/step - loss: 0.0431\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 36s 662ms/step - loss: 0.0194\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 36s 658ms/step - loss: 0.0155\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0132\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0120\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0109\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0103\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0096\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 36s 658ms/step - loss: 0.0093\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0089\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0085\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 34s 637ms/step - loss: 0.0082\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 35s 643ms/step - loss: 0.0081\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 35s 645ms/step - loss: 0.0079\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0081\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 36s 675ms/step - loss: 0.0078\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 38s 700ms/step - loss: 0.0076\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 37s 683ms/step - loss: 0.0075\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 35s 657ms/step - loss: 0.0073\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 35s 657ms/step - loss: 0.0073\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0073\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.0072\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0073\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 36s 663ms/step - loss: 0.0070\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 35s 653ms/step - loss: 0.0070\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 35s 640ms/step - loss: 0.0070\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 35s 642ms/step - loss: 0.0069\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0068\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 34s 636ms/step - loss: 0.0069\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0068\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0068\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 34s 639ms/step - loss: 0.0068\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0067\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0066\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0066\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 35s 645ms/step - loss: 0.0066\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0065\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0065\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.0066\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0066\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 34s 631ms/step - loss: 0.0065\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 34s 631ms/step - loss: 0.0064\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 36s 659ms/step - loss: 0.0064\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0064\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 35s 646ms/step - loss: 0.0065\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0063\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0063\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0063\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 35s 648ms/step - loss: 0.0064\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 34s 639ms/step - loss: 0.0063\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 35s 647ms/step - loss: 0.0062\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0064\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0062\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 35s 654ms/step - loss: 0.0061\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 34s 637ms/step - loss: 0.0061\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0062\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0061\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0062\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0062\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 34s 636ms/step - loss: 0.0061\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 39s 722ms/step - loss: 0.0450\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0189\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0122\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0104\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 39s 716ms/step - loss: 0.0090\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0081\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0077\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0074\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0071\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0073\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0070\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 39s 715ms/step - loss: 0.0068\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0065\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0063\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 39s 721ms/step - loss: 0.0062\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0061\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0061\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 39s 713ms/step - loss: 0.0062\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 40s 733ms/step - loss: 0.0060\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 39s 726ms/step - loss: 0.0058\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0057\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 38s 710ms/step - loss: 0.0056\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0058\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 39s 721ms/step - loss: 0.0056\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 38s 710ms/step - loss: 0.0055\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0054\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0053\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 38s 713ms/step - loss: 0.0054\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 39s 713ms/step - loss: 0.0053\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 41s 751ms/step - loss: 0.0052\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0053\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 39s 726ms/step - loss: 0.0052\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 39s 723ms/step - loss: 0.0051\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0050\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0051\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 39s 716ms/step - loss: 0.0052\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0049\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 38s 709ms/step - loss: 0.0048\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0049\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0049\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0048\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 38s 706ms/step - loss: 0.0047\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0049\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 41s 754ms/step - loss: 0.0049\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 43s 801ms/step - loss: 0.0047\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 43s 804ms/step - loss: 0.0046\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 45s 837ms/step - loss: 0.0046\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 45s 836ms/step - loss: 0.0047\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 45s 829ms/step - loss: 0.0047\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 46s 858ms/step - loss: 0.0046\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 46s 856ms/step - loss: 0.0046\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 45s 829ms/step - loss: 0.0045\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 44s 814ms/step - loss: 0.0044\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 43s 801ms/step - loss: 0.0045\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 44s 816ms/step - loss: 0.0045\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 45s 827ms/step - loss: 0.0046\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 45s 838ms/step - loss: 0.0044\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 44s 807ms/step - loss: 0.0044\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 44s 810ms/step - loss: 0.0043\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 44s 819ms/step - loss: 0.0045\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 48s 893ms/step - loss: 0.0384\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 48s 883ms/step - loss: 0.0169\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 47s 871ms/step - loss: 0.0123\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 47s 869ms/step - loss: 0.0110\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 47s 862ms/step - loss: 0.0093\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 48s 882ms/step - loss: 0.0081\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 47s 878ms/step - loss: 0.0078\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 49s 899ms/step - loss: 0.0072\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 48s 898ms/step - loss: 0.0070\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 52s 962ms/step - loss: 0.0066\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 44s 812ms/step - loss: 0.0065\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 46s 849ms/step - loss: 0.0061\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 47s 862ms/step - loss: 0.0059\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 47s 875ms/step - loss: 0.0058\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 47s 872ms/step - loss: 0.0055\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 47s 870ms/step - loss: 0.0054\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 47s 873ms/step - loss: 0.0053\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 45s 836ms/step - loss: 0.0052\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 43s 805ms/step - loss: 0.0051\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 45s 825ms/step - loss: 0.0049\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 47s 871ms/step - loss: 0.0048\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 47s 874ms/step - loss: 0.0048\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 45s 842ms/step - loss: 0.0046\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 44s 817ms/step - loss: 0.0045\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 44s 810ms/step - loss: 0.0048\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 47s 879ms/step - loss: 0.0047\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 44s 824ms/step - loss: 0.0044\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 45s 828ms/step - loss: 0.0045\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 42s 770ms/step - loss: 0.0045\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 42s 771ms/step - loss: 0.0043\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 42s 769ms/step - loss: 0.0043\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 45s 840ms/step - loss: 0.0049\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 46s 846ms/step - loss: 0.0043\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 45s 842ms/step - loss: 0.0041\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 45s 840ms/step - loss: 0.0041\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 43s 800ms/step - loss: 0.0040\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 43s 797ms/step - loss: 0.0043\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0043\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 45s 829ms/step - loss: 0.0039\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 42s 775ms/step - loss: 0.0040\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 41s 768ms/step - loss: 0.0038\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 41s 761ms/step - loss: 0.0038\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 41s 762ms/step - loss: 0.0038\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 41s 760ms/step - loss: 0.0038\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0036\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0036\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0037\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 41s 758ms/step - loss: 0.0036\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 41s 761ms/step - loss: 0.0037\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 41s 758ms/step - loss: 0.0036\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0034\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 41s 760ms/step - loss: 0.0033\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0034\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 41s 762ms/step - loss: 0.0033\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0035\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 41s 759ms/step - loss: 0.0033\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 41s 761ms/step - loss: 0.0034\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 41s 760ms/step - loss: 0.0033\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 41s 763ms/step - loss: 0.0033\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 41s 764ms/step - loss: 0.0032\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 43s 804ms/step - loss: 0.0932\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0932\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 43s 792ms/step - loss: 0.0932\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0932\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0931\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 43s 792ms/step - loss: 0.0932\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0932\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0931\n",
      "Epoch 17/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 43s 789ms/step - loss: 0.0932\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 43s 792ms/step - loss: 0.0932\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0932\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 43s 791ms/step - loss: 0.0931\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 43s 791ms/step - loss: 0.0932\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0931\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0932\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0931\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 43s 792ms/step - loss: 0.0931\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 43s 798ms/step - loss: 0.0932\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0932\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0931\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0932\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 43s 798ms/step - loss: 0.0931\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0932\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 43s 798ms/step - loss: 0.0932\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 43s 797ms/step - loss: 0.0932\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 43s 797ms/step - loss: 0.0931\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 43s 794ms/step - loss: 0.0932\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 43s 797ms/step - loss: 0.0932\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0931\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0932\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0932\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0932\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 43s 793ms/step - loss: 0.0932\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 43s 796ms/step - loss: 0.0931\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 43s 795ms/step - loss: 0.0931\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 23s 431ms/step - loss: 0.0647\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0290\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0220\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0184\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0162\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0145\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0135\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 23s 425ms/step - loss: 0.0129\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0123\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0122\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0116\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0114\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0111\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0110\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0108\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0106\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0110\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0105\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 23s 421ms/step - loss: 0.0105\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0103\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 23s 422ms/step - loss: 0.0102\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0101\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 23s 421ms/step - loss: 0.0100\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 23s 421ms/step - loss: 0.0099\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0101\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0099\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0098\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0099\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.0096\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0098\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 23s 425ms/step - loss: 0.0095\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 23s 421ms/step - loss: 0.0095\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0094\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0094\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0094\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0093\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0095\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0093\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0093\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0091\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 23s 421ms/step - loss: 0.0091\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0091\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0091\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0092\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0091\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0090\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0090\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0091\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0089\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0089\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0091\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0089\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0091\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0088\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0088\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0087\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0089\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0088\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 23s 420ms/step - loss: 0.0087\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 23s 419ms/step - loss: 0.0087\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 0.0401\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0211\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0161\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0134\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0120\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0111\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0105\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0096\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 0.0092\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0088\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0088\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0084\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0081\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0082\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0079\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0076\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0074\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0073\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0072\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0072\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0071\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0073\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0070\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0070\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0067\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0067\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0068\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0066\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0067\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0065\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 25s 464ms/step - loss: 0.0062\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 0.0062\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0063\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0062\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 0.0062\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0061\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0060\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0061\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0061\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0059\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0059\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0059\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 0.0058\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 0.0057\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0057\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0058\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0057\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0057\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0057\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 25s 461ms/step - loss: 0.0056\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 0.0056\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0057\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0056\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0055\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0055\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0056\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.0057\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 25s 459ms/step - loss: 0.0054\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.0054\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 0.0054\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0450\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0203\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0151\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 26s 482ms/step - loss: 0.0124\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0113\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.0097\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0092\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 26s 482ms/step - loss: 0.0083\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0079\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0076\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0073\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 26s 477ms/step - loss: 0.0073\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 26s 482ms/step - loss: 0.0071\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0068\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.0067\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0064\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0064\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0064\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0062\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0061\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0059\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0058\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0059\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0057\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0056\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 26s 477ms/step - loss: 0.0055\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.0055\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0054\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0054\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0052\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0053\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0051\n",
      "Epoch 33/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0051\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0050\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0050\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.0050\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 26s 482ms/step - loss: 0.0050\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0049\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0049\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0048\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0048\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0048\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0047\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0047\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0045\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0046\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0045\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0045\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0044\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0044\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0044\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 26s 477ms/step - loss: 0.0044\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 0.0044\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0044\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 26s 479ms/step - loss: 0.0044\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 26s 482ms/step - loss: 0.0043\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 26s 483ms/step - loss: 0.0044\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0044\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0043\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 0.0043\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 27s 505ms/step - loss: 0.0412\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0209\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0147\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 27s 493ms/step - loss: 0.0115\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 26s 491ms/step - loss: 0.0102\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0089\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0086\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0077\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0072\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0069\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0067\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0064\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0062\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 27s 492ms/step - loss: 0.0059\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0056\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 27s 492ms/step - loss: 0.0055\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0054\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0053\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0051\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0053\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 27s 492ms/step - loss: 0.0049\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0047\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 27s 493ms/step - loss: 0.0046\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0049\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 27s 492ms/step - loss: 0.0048\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0043\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 27s 493ms/step - loss: 0.0043\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0042\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0042\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0042\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 27s 492ms/step - loss: 0.0040\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0040\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0039\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0040\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0041\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0038\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0038\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0039\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0037\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0037\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0035\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0034\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.0035\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0035\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0033\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0034\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0034\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0032\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.0030\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.0030\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0030\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0031\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0031\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0031\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 27s 493ms/step - loss: 0.0030\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0029\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.0030\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 27s 495ms/step - loss: 0.0029\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.0029\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 27s 491ms/step - loss: 0.0028\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 15s 643ms/step - loss: 0.0311\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0220\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 14s 621ms/step - loss: 0.0206\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 0.0212\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 0.0175\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0166\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0158\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0157\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0147\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0146\n",
      "Epoch 11/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0143\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0144\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 14s 627ms/step - loss: 0.0163\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0145\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0132\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0126\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0124\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0126\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0125\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 14s 621ms/step - loss: 0.0125\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0125\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0126\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0118\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0113\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 0.0112\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0112\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 0.0113\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0111\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 0.0110\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0108\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0108\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0107\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0123\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0107\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0108\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0108\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0109\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 14s 629ms/step - loss: 0.0104\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0107\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0107\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 14s 622ms/step - loss: 0.0104\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 14s 627ms/step - loss: 0.0101\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 14s 629ms/step - loss: 0.0100\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0099\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 14s 621ms/step - loss: 0.0102\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0101\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0099\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0097\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0099\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 14s 627ms/step - loss: 0.0101\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0099\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 0.0100\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0099\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0094\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0095\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 14s 624ms/step - loss: 0.0095\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0092\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 14s 623ms/step - loss: 0.0101\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0122\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 14s 625ms/step - loss: 0.0103\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 16s 716ms/step - loss: 0.0231\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0145\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 16s 702ms/step - loss: 0.0132\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0126\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0114\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0103\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0099\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0090\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0089\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 16s 701ms/step - loss: 0.0086\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0084\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0085\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0081\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0078\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0077\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0074\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0070\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0072\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0069\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0071\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0070\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 16s 702ms/step - loss: 0.0067\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0062\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0061\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0065\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0066\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0065\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0059\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0056\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0057\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0060\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0059\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0059\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0060\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0054\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0054\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0055\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0052\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0052\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0050\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0052\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0050\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0049\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0048\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0048\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0050\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0053\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0050\n",
      "Epoch 49/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 16s 700ms/step - loss: 0.0047\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0046\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0046\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.0045\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 16s 699ms/step - loss: 0.0046\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0045\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0046\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 16s 696ms/step - loss: 0.0043\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 16s 694ms/step - loss: 0.0043\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 16s 698ms/step - loss: 0.0043\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 16s 697ms/step - loss: 0.0042\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 16s 702ms/step - loss: 0.0052\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 18s 771ms/step - loss: 0.0225\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 17s 754ms/step - loss: 0.0142\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0117\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0104\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 17s 745ms/step - loss: 0.0090\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0084\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0079\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0072\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0066\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 17s 746ms/step - loss: 0.0063\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 17s 746ms/step - loss: 0.0061\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0058\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0057\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 17s 751ms/step - loss: 0.0053\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0052\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0054\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0055\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0050\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0046\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0044\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0042\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0041\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0040\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0038\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0038\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 17s 751ms/step - loss: 0.0038\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0037\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0036\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0036\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 17s 751ms/step - loss: 0.0036\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 17s 746ms/step - loss: 0.0038\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 17s 751ms/step - loss: 0.0035\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0035\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0033\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0033\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0033\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0032\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0033\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0032\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0030\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0030\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0030\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0029\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0029\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0029\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0031\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0030\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0029\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 17s 745ms/step - loss: 0.0028\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0028\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0028\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 17s 753ms/step - loss: 0.0028\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0028\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0027\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0026\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0026\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.0026\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 17s 750ms/step - loss: 0.0026\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 17s 749ms/step - loss: 0.0027\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0032\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 18s 804ms/step - loss: 0.1250\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1249\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.1252\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1253\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1249\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1250\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 18s 778ms/step - loss: 0.1250\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1249\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.1249\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1250\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1249\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1249\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1248\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1252\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1249\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 18s 786ms/step - loss: 0.1250\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 18s 784ms/step - loss: 0.1250\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1249\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1249\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1251\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1250\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1249\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1249\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1251\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.1249\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1250\n",
      "Epoch 27/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 18s 778ms/step - loss: 0.1252\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1252\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1252\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1251\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1250\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1251\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1250\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1252\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1250\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1250\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1249\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1249\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1250\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1249\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1250\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1250\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1251\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1249\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1251\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1250\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1249\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1251\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 18s 778ms/step - loss: 0.1250\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1249\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1249\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1250\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.1252\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.1251\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1249\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.1250\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1250\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1250\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.1249\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.1250\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 10s 437ms/step - loss: 0.0373\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0319\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0291\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0277\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0271\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0258\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0254\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0249\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0241\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 10s 421ms/step - loss: 0.0239\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0230\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0227\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0222\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0220\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0218\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0211\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0207\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0205\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0203\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0201\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0196\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0193\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0193\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0190\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0196\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0190\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0187\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0182\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 10s 424ms/step - loss: 0.0182\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0181\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0178\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0179\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0179\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0178\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0182\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0176\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0175\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0171\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0175\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0175\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0174\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0172\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0172\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0166\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0167\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 10s 422ms/step - loss: 0.0169\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0166\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0166\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0166\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0164\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0163\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0162\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0164\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0160\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0164\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0165\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 0.0161\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 10s 421ms/step - loss: 0.0160\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0158\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0162\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0274\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0210\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0185\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0172\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0160\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0149\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0142\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0135\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0136\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 11s 459ms/step - loss: 0.0128\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0120\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 10s 457ms/step - loss: 0.0118\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0117\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0114\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0110\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0106\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0103\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0100\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0107\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0100\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 11s 459ms/step - loss: 0.0099\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0098\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0095\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0095\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0098\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0092\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0091\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0090\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 11s 460ms/step - loss: 0.0091\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0098\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0088\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0089\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0085\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0087\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0085\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0086\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0089\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0083\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0080\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 11s 460ms/step - loss: 0.0080\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0079\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0077\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0079\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 11s 460ms/step - loss: 0.0079\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0078\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0082\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0078\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0078\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0084\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0079\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0077\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0076\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 0.0074\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0074\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0072\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0073\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 11s 459ms/step - loss: 0.0071\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0071\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 0.0073\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 0.0073\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 0.0187\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0136\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0120\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0109\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0109\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0099\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0091\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0086\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0083\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0085\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0079\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0076\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0073\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0072\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0079\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0071\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 11s 479ms/step - loss: 0.0067\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0065\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0067\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0067\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0062\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0060\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0059\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 11s 481ms/step - loss: 0.0062\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 11s 480ms/step - loss: 0.0071\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0061\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0058\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 11s 479ms/step - loss: 0.0057\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0056\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0056\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0060\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0058\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0053\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0053\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0051\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0051\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0050\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0049\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 11s 479ms/step - loss: 0.0051\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0050\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0051\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0049\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0048\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0056\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0053\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0049\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0047\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0046\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0046\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0044\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0044\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 11s 479ms/step - loss: 0.0044\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0045\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0046\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0045\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0043\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 11s 478ms/step - loss: 0.0043\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0042\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 11s 476ms/step - loss: 0.0041\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0041\n",
      "Train for 23 steps\n",
      "Epoch 1/60\n",
      "23/23 [==============================] - 12s 518ms/step - loss: 0.0230\n",
      "Epoch 2/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0153\n",
      "Epoch 3/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0131\n",
      "Epoch 4/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0114\n",
      "Epoch 5/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0101\n",
      "Epoch 6/60\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0096\n",
      "Epoch 7/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0088\n",
      "Epoch 8/60\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0083\n",
      "Epoch 9/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0077\n",
      "Epoch 10/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0074\n",
      "Epoch 11/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0073\n",
      "Epoch 12/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0070\n",
      "Epoch 13/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0064\n",
      "Epoch 14/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0061\n",
      "Epoch 15/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0060\n",
      "Epoch 16/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0057\n",
      "Epoch 17/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0056\n",
      "Epoch 18/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0054\n",
      "Epoch 19/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0053\n",
      "Epoch 20/60\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0054\n",
      "Epoch 21/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0050\n",
      "Epoch 22/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0047\n",
      "Epoch 23/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0046\n",
      "Epoch 24/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0047\n",
      "Epoch 25/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0045\n",
      "Epoch 26/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0043\n",
      "Epoch 27/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0044\n",
      "Epoch 28/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0045\n",
      "Epoch 29/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0042\n",
      "Epoch 30/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0040\n",
      "Epoch 31/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0039\n",
      "Epoch 32/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0037\n",
      "Epoch 33/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0038\n",
      "Epoch 34/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0037\n",
      "Epoch 35/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0037\n",
      "Epoch 36/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0038\n",
      "Epoch 37/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0038\n",
      "Epoch 38/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0036\n",
      "Epoch 39/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0034\n",
      "Epoch 40/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0036\n",
      "Epoch 41/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0037\n",
      "Epoch 42/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0035\n",
      "Epoch 43/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0034\n",
      "Epoch 44/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0032\n",
      "Epoch 45/60\n",
      "23/23 [==============================] - 11s 494ms/step - loss: 0.0033\n",
      "Epoch 46/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0034\n",
      "Epoch 47/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0032\n",
      "Epoch 48/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0031\n",
      "Epoch 49/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0032\n",
      "Epoch 50/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0032\n",
      "Epoch 51/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0036\n",
      "Epoch 52/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0034\n",
      "Epoch 53/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0034\n",
      "Epoch 54/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0031\n",
      "Epoch 55/60\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0030\n",
      "Epoch 56/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0029\n",
      "Epoch 57/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0029\n",
      "Epoch 58/60\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0029\n",
      "Epoch 59/60\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0029\n",
      "Epoch 60/60\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "for train_item in train_data_map.items():\n",
    "    train_data = train_item[0]\n",
    "    train_name = train_item[1]\n",
    "    for model_item in {**model_w_map , **model_n_map}.items():\n",
    "        model = model_item[0]\n",
    "        model_name = model_item[1]\n",
    "        checkpoint_basename = train_name + \"_\" + model_name\n",
    "        checkpoint_path = os.path.join(CHECKPOINTS_DIR,checkpoint_basename)\n",
    "        \n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        \n",
    "        model_weights_file = os.path.join(checkpoint_path, \"cp.ckpt\")\n",
    "        log_path = os.path.join(checkpoint_path, \"log\")\n",
    "        \n",
    "        # Callback to save the model's weights\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_weights_file,\n",
    "                                                         save_weights_only=True)\n",
    "        \n",
    "        model.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "        \n",
    "        needs_training = True\n",
    "        if os.path.exists(model_weights_file) and RESUME_MODELS:\n",
    "            model.load_weights(model_weights_file)\n",
    "            needs_training = False\n",
    "        \n",
    "        if TRAIN_MODELS or needs_training:\n",
    "            history = model.fit(train_data,\n",
    "                                epochs = NUM_EPOCHS,\n",
    "                                steps_per_epoch = steps_per_epoch_map[train_data],\n",
    "                                callbacks = [TensorBoard(log_dir=log_path),\n",
    "                                             cp_callback]\n",
    "                               )\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training with different barcode orientation improves segmentation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_1'></a>\n",
    "1. Alessandro Zamberletti, Ignazio Gallo, Moreno Carullo and Elisabetta Binaghi \"Neural Image Restoration For Decoding 1-D Barcodes Using Common Camera Phones\" Computer Vision, Imaging and Computer Graphics. Theory and Applications, Springer Berlin Heidelberg, 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_2'></a>\n",
    "2. S. Wachenfeld, S. Terlunen, X.Jiang  \"Robust recognition of 1-d barcodes using camera phones.\"\"\n",
    "In Proceedings of the 2008 19th International Conference on Pattern Recognition, Tampa, FL, USA,\n",
    "8–11 December 2008; pp. 1–4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_3'></a>\n",
    "3. Alessandro Zamberletti, Ignazio Gallo and Simone Albertini \"Robust Angle Invariant 1D Barcode Detection\" Proceedings of the 2nd Asian Conference on Pattern Recognition (ACPR), Okinawa, Japan, 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
