{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barcode Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcodes are widely used to localize items on images. Numerous applications are available to find and recognize the barcodes. However they cannot manage cases such as targets with small scale, oclusions, shape deformations, noise and blurring. The most widely solutions require the barcode to be oriented in single directions and may fail in conditions that seem without problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work attempts to solve the problem of barcode localization using a deep learning based segmentation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the folder where the images datasets are loaded/present and where the \n",
    "WORKPLACE_FOLDER = \"/tmp\"\n",
    "\n",
    "# Folder to store/read checkpoints for model training\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "\n",
    "# Image size for the input\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Image size + channels for the input\n",
    "INPUT_IMAGE_SIZE = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "\n",
    "RESUME_MODELS = True\n",
    "TRAIN_MODELS = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total five datasets are used - two to train the neural network and three to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First three datasets are downloaded from http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html (ARTELAB) [[1](#ref_1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks for the segments containing barcodes were created using the [pyzbar](https://pypi.org/project/pyzbar/pyzbar) library. For this purpose the image was rotated with predefined steps and the obtained from [pyzbar](https://pypi.org/project/pyzbar/pyzbar) points were used to set the required segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has to be noted that the [pyzbar](https://pypi.org/project/pyzbar/pyzbar) did not produced reliable results even for some images that seemed without defects. For this reason not all the images from [ARTELAB](http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html) were used. Only the successfully generated masks were applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices with autofocus - first subset.\n",
    "Contains 122 images (originals + masks) with zipped size 38,5 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 18MFEr2iekIojLwEhzswOIyW_Fp8CNQA5 into /tmp/Dataset1.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"18MFEr2iekIojLwEhzswOIyW_Fp8CNQA5\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset1.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices with autofocus - first subset.\n",
    "Contains 76 images (originals + masks) with zipped size 124,5 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1SHJi744MZV40Mp38m6RW8PeuQktbEt6u into /tmp/Dataset2.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1SHJi744MZV40Mp38m6RW8PeuQktbEt6u\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset2.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pictures of barcodes taken from devices without autofocus. Contains 61 images (originals + masks) with zipped size 13,6 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1ybx4TiciMoQcpVi3fAzZoUOuSg2WPrvI into /tmp/Dataset3.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1ybx4TiciMoQcpVi3fAzZoUOuSg2WPrvI\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset3.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded from https://github.com/rohrlaf/SlaRle.js/tree/master/Muenster%20BarcodeDB and referenced as Muenster BarodeDB [[2](#ref_2)]. Masks were prepared following the above mentioned procedure with [pyzbar](https://pypi.org/project/pyzbar/pyzbar) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains 863 images (originals + masks) with zipped size 46,9 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1gfxKTaG7tHDDK5fPQW6PH-Zcbx7KPXzO into /tmp/Dataset4.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1gfxKTaG7tHDDK5fPQW6PH-Zcbx7KPXzO\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset4.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded from http://artelab.dista.uninsubria.it/downloads/datasets/barcode/hough_barcode_1d/hough_barcode_1d.html (ARTELAB) [[3](#ref_3)] Referenced as dataset no.2 plain (1d_barcode_extended_plain.zip) contains only the images and the detection masks. Masks had to be adjusted to be grayscale one channel images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains 365 images (originals + masks) with zipped size 37,5 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1rNi26q-iq5Q4BtrIOT-pDSleCtKzw3pk into /tmp/Dataset5.zip... Done.\n",
      "Unzipping...Done.\n"
     ]
    }
   ],
   "source": [
    "gdd.download_file_from_google_drive(file_id=\"1rNi26q-iq5Q4BtrIOT-pDSleCtKzw3pk\",\n",
    "                                    dest_path=os.path.join(WORKPLACE_FOLDER, \"Dataset5.zip\"),\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filenames(base_dir):\n",
    "    \"\"\"\n",
    "    Returns the filenames for barcodes and masks\n",
    "    Assumes the following structure:\n",
    "    |---base_dir\n",
    "    | |---Original\n",
    "    | | |---image1.jpg\n",
    "    | | |---image2.jpg\n",
    "    | |---Detection\n",
    "    | | |---image1.png\n",
    "    | | |---image2.png\n",
    "    \n",
    "    :param base_dir: directories where image databse is stored\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filenames = {}\n",
    "    filenames[\"Original\"] = []\n",
    "    filenames[\"Detection\"] = []\n",
    "    \n",
    "    # True if image is to be rotated counter-clockwise by 90 degrees.\n",
    "    filenames[\"Rotation\"] = []\n",
    "    \n",
    "    original_directory = os.path.join(base_dir,\"Original\")\n",
    "    detection_directory = os.path.join(base_dir,\"Detection\")\n",
    "    for file_name in os.listdir(original_directory):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            original_name = os.path.join(original_directory, file_name)\n",
    "            base_filename=os.path.splitext(file_name)[0]\n",
    "            detection_name = os.path.join(detection_directory, base_filename + \".png\")\n",
    "            if os.path.exists(detection_name):\n",
    "                filenames[\"Rotation\"].append(True)\n",
    "                filenames[\"Original\"].append(original_name)\n",
    "                filenames[\"Detection\"].append(detection_name)\n",
    "                filenames[\"Rotation\"].append(False)\n",
    "                filenames[\"Original\"].append(original_name)\n",
    "                filenames[\"Detection\"].append(detection_name)\n",
    "        \n",
    "    return pd.DataFrame(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_dataset_1 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset1\"))\n",
    "filenames_dataset_2 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset2\"))\n",
    "filenames_dataset_3 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset3\"))\n",
    "filenames_dataset_4 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset4\"))\n",
    "filenames_dataset_5 = get_all_filenames(os.path.join(WORKPLACE_FOLDER, \"Dataset5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_1.shape[0] == 244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_2.shape[0] == 152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_3.shape[0] == 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_4.shape[0] == 1726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filenames_dataset_5.shape[0] == 730)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(x):\n",
    "    # Normalize\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[..., ::-1]\n",
    "    return x\n",
    "\n",
    "def read_and_prepare_image(original_image_filename, mask_image_filename, is_rotated):\n",
    "    # Get images\n",
    "    original_image = tf.io.read_file(original_image_filename)\n",
    "    original_image_decoded = tf.image.decode_jpeg(original_image)\n",
    "    mask_image = tf.io.read_file(mask_image_filename)\n",
    "    mask_image_decoded = tf.image.decode_jpeg(mask_image)\n",
    "    \n",
    "    # Resize\n",
    "    original_image_resized = tf.image.resize(original_image_decoded, IMAGE_SIZE)\n",
    "    mask_image_resized = tf.image.resize(mask_image_decoded, IMAGE_SIZE)\n",
    "    \n",
    "    # Rotate\n",
    "    if is_rotated:\n",
    "        original_image_resized = tf.image.rot90(original_image_resized)\n",
    "        mask_image_resized = tf.image.rot90(mask_image_resized)\n",
    "\n",
    "    original_image_tensor = preprocess_image(original_image_resized)\n",
    "    mask_image_tensor = preprocess_image(mask_image_resized)\n",
    "    \n",
    "    return original_image_tensor, mask_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tf_dataset(data, should_batch = True, should_repeat = True):\n",
    "    dataset_initial = tf.data.Dataset.from_tensor_slices((data.Original.values, data.Detection.values, data.Rotation.values))\n",
    "    dataset_mapped = dataset_initial.map(read_and_prepare_image)\n",
    "    dataset_shuffled = dataset_mapped.shuffle(buffer_size = len(data))\n",
    "    \n",
    "    if should_batch:\n",
    "        dataset = dataset_shuffled.batch(BATCH_SIZE)\n",
    "    else:\n",
    "        dataset = dataset_shuffled.batch(len(data))\n",
    "        \n",
    "    if should_repeat:\n",
    "        dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = initialize_tf_dataset(filenames_dataset_4)\n",
    "train_data_2 = initialize_tf_dataset(filenames_dataset_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_map = {\n",
    "    train_data_1 : \"train1\",\n",
    "    train_data_2 : \"train2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = initialize_tf_dataset(filenames_dataset_1, should_batch = False, should_repeat = False)\n",
    "test_data_2 = initialize_tf_dataset(filenames_dataset_2, should_batch = False, should_repeat = False)\n",
    "test_data_3 = initialize_tf_dataset(filenames_dataset_3, should_batch = False, should_repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_map = {\n",
    "    test_data_1 : \"test1\",\n",
    "    test_data_2 : \"test2\",\n",
    "    test_data_3 : \"test3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_data_map.keys():\n",
    "    for batch in data:\n",
    "        assert(batch[0].shape[0] == BATCH_SIZE)\n",
    "        assert(batch[0].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[0].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[0].shape[3] == INPUT_IMAGE_SIZE[2])\n",
    "        assert(batch[1].shape[0] == BATCH_SIZE)\n",
    "        assert(batch[1].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[1].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[1].shape[3] == 1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, filenames in zip(test_data_map.keys(),\n",
    "                           [filenames_dataset_1, filenames_dataset_2, filenames_dataset_3]):\n",
    "    for batch in data:\n",
    "        assert(batch[0].shape[0] == filenames.shape[0])\n",
    "        assert(batch[0].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[0].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[0].shape[3] == INPUT_IMAGE_SIZE[2])\n",
    "        assert(batch[1].shape[0] == filenames.shape[0])\n",
    "        assert(batch[1].shape[1] == INPUT_IMAGE_SIZE[0])\n",
    "        assert(batch[1].shape[2] == INPUT_IMAGE_SIZE[1])\n",
    "        assert(batch[1].shape[3] == 1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_4lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_5lw():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(128,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(128, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w_map = {\n",
    "    get_model_2lw() : \"model2lw\",\n",
    "    get_model_3lw() : \"model3lw\",\n",
    "    get_model_4lw() : \"model4lw\",\n",
    "    get_model_5lw() : \"model5lw\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_2ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_4ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_5ln():\n",
    "    model = Sequential([\n",
    "        Input(INPUT_IMAGE_SIZE),\n",
    "        Conv2D(4,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(8,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(16,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(32,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64,(3,3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2,2), padding='same'),\n",
    "        Conv2D(64, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(8, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(4, (3, 3), activation=tf.keras.activations.relu, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (1, 1), activation=tf.keras.activations.relu, padding='same')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n_map = {\n",
    "    get_model_2ln() : \"model2ln\",\n",
    "    get_model_3ln() : \"model3ln\",\n",
    "    get_model_4ln() : \"model4ln\",\n",
    "    get_model_5ln() : \"model5ln\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 8)       32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,305\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 5,417\n",
      "Trainable params: 5,385\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 21,673\n",
      "Trainable params: 21,609\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 86,441\n",
      "Trainable params: 86,313\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in model_w_map.keys():\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 8)       32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,305\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 5,417\n",
      "Trainable params: 5,385\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 21,673\n",
      "Trainable params: 21,609\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 224, 224, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 112, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 112, 112, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 56, 56, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 56, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 112, 112, 4)       292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling (None, 224, 224, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 224, 224, 1)       5         \n",
      "=================================================================\n",
      "Total params: 86,441\n",
      "Trainable params: 86,313\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in model_n_map.keys():\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_train_1 = round(len(filenames_dataset_4) * 1.0 / BATCH_SIZE)\n",
    "steps_per_epoch_train_2 = round(len(filenames_dataset_5) * 1.0 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_map = {\n",
    "    train_data_1 : steps_per_epoch_train_1,\n",
    "    train_data_2 : steps_per_epoch_train_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CHECKPOINTS_DIR):\n",
    "    os.makedirs(CHECKPOINTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 36s 666ms/step - loss: 0.0431\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 36s 662ms/step - loss: 0.0194\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 36s 658ms/step - loss: 0.0155\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0132\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0120\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0109\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0103\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0096\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 36s 658ms/step - loss: 0.0093\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0089\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0085\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 34s 637ms/step - loss: 0.0082\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 35s 643ms/step - loss: 0.0081\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 35s 645ms/step - loss: 0.0079\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0081\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 36s 675ms/step - loss: 0.0078\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 38s 700ms/step - loss: 0.0076\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 37s 683ms/step - loss: 0.0075\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 35s 657ms/step - loss: 0.0073\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 35s 657ms/step - loss: 0.0073\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0073\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.0072\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0073\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 36s 663ms/step - loss: 0.0070\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 35s 653ms/step - loss: 0.0070\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 35s 640ms/step - loss: 0.0070\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 35s 642ms/step - loss: 0.0069\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0068\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 34s 636ms/step - loss: 0.0069\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0068\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0068\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 34s 639ms/step - loss: 0.0068\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0067\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0066\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0066\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 35s 645ms/step - loss: 0.0066\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0065\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0065\n",
      "Epoch 39/60\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.0066\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0066\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 34s 631ms/step - loss: 0.0065\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 34s 631ms/step - loss: 0.0064\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 36s 659ms/step - loss: 0.0064\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0064\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 35s 646ms/step - loss: 0.0065\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0063\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 0.0063\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0063\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 35s 648ms/step - loss: 0.0064\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 34s 639ms/step - loss: 0.0063\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 35s 647ms/step - loss: 0.0062\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 0.0064\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0062\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 35s 654ms/step - loss: 0.0061\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 34s 637ms/step - loss: 0.0061\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 35s 639ms/step - loss: 0.0062\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0061\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 34s 634ms/step - loss: 0.0062\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 0.0062\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 34s 636ms/step - loss: 0.0061\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 39s 722ms/step - loss: 0.0450\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0189\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0122\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0104\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 39s 716ms/step - loss: 0.0090\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0081\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0077\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0074\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 43s 790ms/step - loss: 0.0071\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0073\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0070\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 39s 715ms/step - loss: 0.0068\n",
      "Epoch 13/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0065\n",
      "Epoch 14/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0063\n",
      "Epoch 15/60\n",
      "54/54 [==============================] - 39s 721ms/step - loss: 0.0062\n",
      "Epoch 16/60\n",
      "54/54 [==============================] - 39s 718ms/step - loss: 0.0061\n",
      "Epoch 17/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0061\n",
      "Epoch 18/60\n",
      "54/54 [==============================] - 39s 713ms/step - loss: 0.0062\n",
      "Epoch 19/60\n",
      "54/54 [==============================] - 40s 733ms/step - loss: 0.0060\n",
      "Epoch 20/60\n",
      "54/54 [==============================] - 39s 726ms/step - loss: 0.0058\n",
      "Epoch 21/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0057\n",
      "Epoch 22/60\n",
      "54/54 [==============================] - 38s 710ms/step - loss: 0.0056\n",
      "Epoch 23/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0058\n",
      "Epoch 24/60\n",
      "54/54 [==============================] - 39s 721ms/step - loss: 0.0056\n",
      "Epoch 25/60\n",
      "54/54 [==============================] - 38s 710ms/step - loss: 0.0055\n",
      "Epoch 26/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0054\n",
      "Epoch 27/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0053\n",
      "Epoch 28/60\n",
      "54/54 [==============================] - 38s 713ms/step - loss: 0.0054\n",
      "Epoch 29/60\n",
      "54/54 [==============================] - 39s 713ms/step - loss: 0.0053\n",
      "Epoch 30/60\n",
      "54/54 [==============================] - 41s 751ms/step - loss: 0.0052\n",
      "Epoch 31/60\n",
      "54/54 [==============================] - 39s 719ms/step - loss: 0.0053\n",
      "Epoch 32/60\n",
      "54/54 [==============================] - 39s 726ms/step - loss: 0.0052\n",
      "Epoch 33/60\n",
      "54/54 [==============================] - 39s 723ms/step - loss: 0.0051\n",
      "Epoch 34/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0050\n",
      "Epoch 35/60\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0051\n",
      "Epoch 36/60\n",
      "54/54 [==============================] - 39s 716ms/step - loss: 0.0052\n",
      "Epoch 37/60\n",
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0049\n",
      "Epoch 38/60\n",
      "54/54 [==============================] - 38s 709ms/step - loss: 0.0048\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 38s 712ms/step - loss: 0.0049\n",
      "Epoch 40/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0049\n",
      "Epoch 41/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0048\n",
      "Epoch 42/60\n",
      "54/54 [==============================] - 38s 706ms/step - loss: 0.0047\n",
      "Epoch 43/60\n",
      "54/54 [==============================] - 38s 711ms/step - loss: 0.0049\n",
      "Epoch 44/60\n",
      "54/54 [==============================] - 41s 754ms/step - loss: 0.0049\n",
      "Epoch 45/60\n",
      "54/54 [==============================] - 43s 801ms/step - loss: 0.0047\n",
      "Epoch 46/60\n",
      "54/54 [==============================] - 43s 804ms/step - loss: 0.0046\n",
      "Epoch 47/60\n",
      "54/54 [==============================] - 45s 837ms/step - loss: 0.0046\n",
      "Epoch 48/60\n",
      "54/54 [==============================] - 45s 836ms/step - loss: 0.0047\n",
      "Epoch 49/60\n",
      "54/54 [==============================] - 45s 829ms/step - loss: 0.0047\n",
      "Epoch 50/60\n",
      "54/54 [==============================] - 46s 858ms/step - loss: 0.0046\n",
      "Epoch 51/60\n",
      "54/54 [==============================] - 46s 856ms/step - loss: 0.0046\n",
      "Epoch 52/60\n",
      "54/54 [==============================] - 45s 829ms/step - loss: 0.0045\n",
      "Epoch 53/60\n",
      "54/54 [==============================] - 44s 814ms/step - loss: 0.0044\n",
      "Epoch 54/60\n",
      "54/54 [==============================] - 43s 801ms/step - loss: 0.0045\n",
      "Epoch 55/60\n",
      "54/54 [==============================] - 44s 816ms/step - loss: 0.0045\n",
      "Epoch 56/60\n",
      "54/54 [==============================] - 45s 827ms/step - loss: 0.0046\n",
      "Epoch 57/60\n",
      "54/54 [==============================] - 45s 838ms/step - loss: 0.0044\n",
      "Epoch 58/60\n",
      "54/54 [==============================] - 44s 807ms/step - loss: 0.0044\n",
      "Epoch 59/60\n",
      "54/54 [==============================] - 44s 810ms/step - loss: 0.0043\n",
      "Epoch 60/60\n",
      "54/54 [==============================] - 44s 819ms/step - loss: 0.0045\n",
      "Train for 54 steps\n",
      "Epoch 1/60\n",
      "54/54 [==============================] - 48s 893ms/step - loss: 0.0384\n",
      "Epoch 2/60\n",
      "54/54 [==============================] - 48s 883ms/step - loss: 0.0169\n",
      "Epoch 3/60\n",
      "54/54 [==============================] - 47s 871ms/step - loss: 0.0123\n",
      "Epoch 4/60\n",
      "54/54 [==============================] - 47s 869ms/step - loss: 0.0110\n",
      "Epoch 5/60\n",
      "54/54 [==============================] - 47s 862ms/step - loss: 0.0093\n",
      "Epoch 6/60\n",
      "54/54 [==============================] - 48s 882ms/step - loss: 0.0081\n",
      "Epoch 7/60\n",
      "54/54 [==============================] - 47s 878ms/step - loss: 0.0078\n",
      "Epoch 8/60\n",
      "54/54 [==============================] - 49s 899ms/step - loss: 0.0072\n",
      "Epoch 9/60\n",
      "54/54 [==============================] - 48s 898ms/step - loss: 0.0070\n",
      "Epoch 10/60\n",
      "54/54 [==============================] - 52s 962ms/step - loss: 0.0066\n",
      "Epoch 11/60\n",
      "54/54 [==============================] - 44s 812ms/step - loss: 0.0065\n",
      "Epoch 12/60\n",
      "54/54 [==============================] - 46s 849ms/step - loss: 0.0061\n",
      "Epoch 13/60\n",
      "31/54 [================>.............] - ETA: 20s - loss: 0.0060"
     ]
    }
   ],
   "source": [
    "for train_item in train_data_map.items():\n",
    "    train_data = train_item[0]\n",
    "    train_name = train_item[1]\n",
    "    for model_item in {**model_w_map , **model_n_map}.items():\n",
    "        model = model_item[0]\n",
    "        model_name = model_item[1]\n",
    "        checkpoint_basename = train_name + \"_\" + model_name\n",
    "        checkpoint_path = os.path.join(CHECKPOINTS_DIR,checkpoint_basename)\n",
    "        \n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path)\n",
    "        \n",
    "        model_weights_file = os.path.join(checkpoint_path, \"cp.ckpt\")\n",
    "        log_path = os.path.join(checkpoint_path, \"log\")\n",
    "        \n",
    "        # Callback to save the model's weights\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_weights_file,\n",
    "                                                         save_weights_only=True)\n",
    "        \n",
    "        model.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "        \n",
    "        needs_training = True\n",
    "        if os.path.exists(model_weights_file) and RESUME_MODELS:\n",
    "            model.load_weights(model_weights_file)\n",
    "            needs_training = False\n",
    "        \n",
    "        if TRAIN_MODELS or needs_training:\n",
    "            history = model.fit(train_data,\n",
    "                                epochs = NUM_EPOCHS,\n",
    "                                steps_per_epoch = steps_per_epoch_map[train_data],\n",
    "                                callbacks = [TensorBoard(log_dir=log_path),\n",
    "                                             cp_callback]\n",
    "                               )\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training with different barcode orientation improves segmentation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_1'></a>\n",
    "1. Alessandro Zamberletti, Ignazio Gallo, Moreno Carullo and Elisabetta Binaghi \"Neural Image Restoration For Decoding 1-D Barcodes Using Common Camera Phones\" Computer Vision, Imaging and Computer Graphics. Theory and Applications, Springer Berlin Heidelberg, 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_2'></a>\n",
    "2. S. Wachenfeld, S. Terlunen, X.Jiang  \"Robust recognition of 1-d barcodes using camera phones.\"\"\n",
    "In Proceedings of the 2008 19th International Conference on Pattern Recognition, Tampa, FL, USA,\n",
    "811 December 2008; pp. 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref_3'></a>\n",
    "3. Alessandro Zamberletti, Ignazio Gallo and Simone Albertini \"Robust Angle Invariant 1D Barcode Detection\" Proceedings of the 2nd Asian Conference on Pattern Recognition (ACPR), Okinawa, Japan, 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
